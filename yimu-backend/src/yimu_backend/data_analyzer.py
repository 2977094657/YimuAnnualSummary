# -*- coding: utf-8 -*-
"""
æ•°æ®åˆ†ææ¨¡å—
æä¾›ä¸€æœ¨è®°è´¦æ•°æ®çš„å„ç§ç»Ÿè®¡åˆ†æåŠŸèƒ½
"""

import sqlite3
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from loguru import logger
import os
from collections import Counter


class YimuDataAnalyzer:
    """ä¸€æœ¨è®°è´¦æ•°æ®åˆ†æå™¨"""
    
    def __init__(self, db_path: str = "output/yimu_data.db"):
        self.db_path = db_path
        
    def _get_connection(self) -> sqlite3.Connection:
        """è·å–æ•°æ®åº“è¿æ¥"""
        if not os.path.exists(self.db_path):
            raise FileNotFoundError(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.db_path}")
        return sqlite3.connect(self.db_path)
        
    def get_monthly_trend(self, year: Optional[int] = None) -> Dict:
        """è·å–æœˆåº¦æ”¶æ”¯è¶‹åŠ¿
        
        Args:
            year: æŒ‡å®šå¹´ä»½ï¼Œé»˜è®¤ä¸ºå½“å‰å¹´ä»½
            
        Returns:
            Dict: æœˆåº¦è¶‹åŠ¿æ•°æ®
        """
        try:
            conn = self._get_connection()
            
            if year is None:
                year = datetime.now().year
                
            query = """
            SELECT 
                strftime('%m', date) as month,
                type,
                SUM(amount) as total_amount,
                COUNT(*) as transaction_count
            FROM transactions 
            WHERE strftime('%Y', date) = ?
            GROUP BY month, type
            ORDER BY month
            """
            
            df = pd.read_sql_query(query, conn, params=[str(year)])
            conn.close()
            
            # é‡ç»„æ•°æ®
            result = {}
            for month in range(1, 13):
                month_str = f"{month:02d}"
                month_data = df[df['month'] == month_str]
                
                income = month_data[month_data['type'] == 'æ”¶å…¥']['total_amount'].sum()
                expense = abs(month_data[month_data['type'] == 'æ”¯å‡º']['total_amount'].sum())
                
                result[month_str] = {
                    'month': month_str,
                    'income': float(income) if income else 0.0,
                    'expense': float(expense) if expense else 0.0,
                    'net': float(income - expense) if (income or expense) else 0.0,
                    'transaction_count': int(month_data['transaction_count'].sum()) if not month_data.empty else 0
                }
                
            logger.info(f"è·å–{year}å¹´æœˆåº¦è¶‹åŠ¿æ•°æ®æˆåŠŸ")
            return {
                'year': year,
                'monthly_data': result
            }
            
        except Exception as e:
            logger.error(f"è·å–æœˆåº¦è¶‹åŠ¿æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
            
    def get_category_analysis(self, transaction_type: str = 'æ”¯å‡º', year: Optional[int] = None) -> Dict:
        """è·å–åˆ†ç±»åˆ†æ
        
        Args:
            transaction_type: äº¤æ˜“ç±»å‹ï¼ˆæ”¶å…¥/æ”¯å‡ºï¼‰
            year: æŒ‡å®šå¹´ä»½
            
        Returns:
            Dict: åˆ†ç±»åˆ†ææ•°æ®
        """
        try:
            conn = self._get_connection()
            
            year_filter = ""
            params = [transaction_type]
            if year:
                year_filter = "AND strftime('%Y', date) = ?"
                params.append(str(year))
                
            query = f"""
            SELECT 
                category,
                subcategory,
                SUM(ABS(amount)) as total_amount,
                COUNT(*) as transaction_count,
                AVG(ABS(amount)) as avg_amount
            FROM transactions 
            WHERE type = ? {year_filter}
            GROUP BY category, subcategory
            ORDER BY total_amount DESC
            """
            
            df = pd.read_sql_query(query, conn, params=params)
            conn.close()
            
            # æŒ‰ä¸»åˆ†ç±»æ±‡æ€»
            category_summary = df.groupby('category').agg({
                'total_amount': 'sum',
                'transaction_count': 'sum',
                'avg_amount': 'mean'
            }).reset_index()
            
            category_summary = category_summary.sort_values('total_amount', ascending=False)
            
            # è®¡ç®—ç™¾åˆ†æ¯”
            total_amount = category_summary['total_amount'].sum()
            category_summary['percentage'] = (category_summary['total_amount'] / total_amount * 100).round(2)
            
            result = {
                'transaction_type': transaction_type,
                'year': year,
                'total_amount': float(total_amount),
                'categories': [],
                'subcategories': []
            }
            
            # ä¸»åˆ†ç±»æ•°æ®
            for _, row in category_summary.iterrows():
                result['categories'].append({
                    'category': row['category'],
                    'amount': float(row['total_amount']),
                    'count': int(row['transaction_count']),
                    'avg_amount': float(row['avg_amount']),
                    'percentage': float(row['percentage'])
                })
                
            # å­åˆ†ç±»æ•°æ®
            for _, row in df.iterrows():
                result['subcategories'].append({
                    'category': row['category'],
                    'subcategory': row['subcategory'],
                    'amount': float(row['total_amount']),
                    'count': int(row['transaction_count']),
                    'avg_amount': float(row['avg_amount'])
                })
                
            logger.info(f"è·å–{transaction_type}åˆ†ç±»åˆ†ææ•°æ®æˆåŠŸ")
            return result
            
        except Exception as e:
            logger.error(f"è·å–åˆ†ç±»åˆ†ææ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
            
    def get_account_analysis(self, year: Optional[int] = None) -> Dict:
        """è·å–è´¦æˆ·ä½¿ç”¨åˆ†æ
        
        Args:
            year: æŒ‡å®šå¹´ä»½
            
        Returns:
            Dict: è´¦æˆ·åˆ†ææ•°æ®
        """
        try:
            conn = self._get_connection()
            
            year_filter = ""
            params = []
            if year:
                year_filter = "WHERE strftime('%Y', date) = ?"
                params.append(str(year))
                
            query = f"""
            SELECT 
                account,
                type,
                SUM(ABS(amount)) as total_amount,
                COUNT(*) as transaction_count
            FROM transactions 
            {year_filter}
            GROUP BY account, type
            ORDER BY total_amount DESC
            """
            
            df = pd.read_sql_query(query, conn, params=params)
            conn.close()
            
            # æŒ‰è´¦æˆ·æ±‡æ€»
            account_summary = df.groupby('account').agg({
                'total_amount': 'sum',
                'transaction_count': 'sum'
            }).reset_index()
            
            account_summary = account_summary.sort_values('total_amount', ascending=False)
            
            result = {
                'year': year,
                'accounts': [],
                'account_type_breakdown': []
            }
            
            # è´¦æˆ·æ±‡æ€»æ•°æ®
            for _, row in account_summary.iterrows():
                result['accounts'].append({
                    'account': row['account'],
                    'total_amount': float(row['total_amount']),
                    'transaction_count': int(row['transaction_count'])
                })
                
            # è´¦æˆ·ç±»å‹æ˜ç»†
            for _, row in df.iterrows():
                result['account_type_breakdown'].append({
                    'account': row['account'],
                    'type': row['type'],
                    'amount': float(row['total_amount']),
                    'count': int(row['transaction_count'])
                })
                
            logger.info(f"è·å–è´¦æˆ·åˆ†ææ•°æ®æˆåŠŸ")
            return result
            
        except Exception as e:
            logger.error(f"è·å–è´¦æˆ·åˆ†ææ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
            
    def get_location_analysis(self, year: Optional[int] = None, limit: int = 20) -> Dict:
        """è·å–æ¶ˆè´¹åœ°ç‚¹åˆ†æ
        
        Args:
            year: æŒ‡å®šå¹´ä»½
            limit: è¿”å›è®°å½•æ•°é™åˆ¶
            
        Returns:
            Dict: åœ°ç‚¹åˆ†ææ•°æ®
        """
        try:
            conn = self._get_connection()
            
            year_filter = ""
            params = []
            if year:
                year_filter = "AND strftime('%Y', date) = ?"
                params.append(str(year))
                
            query = f"""
            SELECT 
                address,
                SUM(ABS(amount)) as total_amount,
                COUNT(*) as transaction_count,
                AVG(ABS(amount)) as avg_amount
            FROM transactions 
            WHERE address != '' AND address IS NOT NULL {year_filter}
            GROUP BY address
            ORDER BY total_amount DESC
            LIMIT ?
            """
            
            params.append(limit)
            df = pd.read_sql_query(query, conn, params=params)
            conn.close()
            
            result = {
                'year': year,
                'locations': []
            }
            
            for _, row in df.iterrows():
                result['locations'].append({
                    'address': row['address'],
                    'total_amount': float(row['total_amount']),
                    'transaction_count': int(row['transaction_count']),
                    'avg_amount': float(row['avg_amount'])
                })
                
            logger.info(f"è·å–åœ°ç‚¹åˆ†ææ•°æ®æˆåŠŸ")
            return result
            
        except Exception as e:
            logger.error(f"è·å–åœ°ç‚¹åˆ†ææ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
            
    def get_time_pattern_analysis(self, year: Optional[int] = None) -> Dict:
        """è·å–æ—¶é—´æ¨¡å¼åˆ†æ
        
        Args:
            year: æŒ‡å®šå¹´ä»½
            
        Returns:
            Dict: æ—¶é—´æ¨¡å¼åˆ†ææ•°æ®
        """
        try:
            conn = self._get_connection()
            
            year_filter = ""
            params = []
            if year:
                year_filter = "WHERE strftime('%Y', date) = ?"
                params.append(str(year))
                
            # æŒ‰å°æ—¶ç»Ÿè®¡
            hour_query = f"""
            SELECT 
                strftime('%H', date) as hour,
                COUNT(*) as transaction_count,
                SUM(ABS(amount)) as total_amount
            FROM transactions 
            {year_filter}
            GROUP BY hour
            ORDER BY hour
            """
            
            # æŒ‰æ˜ŸæœŸç»Ÿè®¡
            weekday_query = f"""
            SELECT 
                strftime('%w', date) as weekday,
                COUNT(*) as transaction_count,
                SUM(ABS(amount)) as total_amount
            FROM transactions 
            {year_filter}
            GROUP BY weekday
            ORDER BY weekday
            """
            
            hour_df = pd.read_sql_query(hour_query, conn, params=params)
            weekday_df = pd.read_sql_query(weekday_query, conn, params=params)
            conn.close()
            
            # æ˜ŸæœŸæ˜ å°„
            weekday_names = ['å‘¨æ—¥', 'å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­']
            
            result = {
                'year': year,
                'hourly_pattern': [],
                'weekday_pattern': []
            }
            
            # å°æ—¶æ¨¡å¼
            for _, row in hour_df.iterrows():
                result['hourly_pattern'].append({
                    'hour': int(row['hour']),
                    'transaction_count': int(row['transaction_count']),
                    'total_amount': float(row['total_amount'])
                })
                
            # æ˜ŸæœŸæ¨¡å¼
            for _, row in weekday_df.iterrows():
                weekday_idx = int(row['weekday'])
                result['weekday_pattern'].append({
                    'weekday': weekday_idx,
                    'weekday_name': weekday_names[weekday_idx],
                    'transaction_count': int(row['transaction_count']),
                    'total_amount': float(row['total_amount'])
                })
                
            logger.info(f"è·å–æ—¶é—´æ¨¡å¼åˆ†ææ•°æ®æˆåŠŸ")
            return result
            
        except Exception as e:
            logger.error(f"è·å–æ—¶é—´æ¨¡å¼åˆ†ææ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
            
    def get_financial_overview(self, year: Optional[int] = None) -> Dict:
        """è·å–å¹´åº¦è´¢åŠ¡æ€»è§ˆ
        
        Args:
            year: æŒ‡å®šå¹´ä»½
            
        Returns:
            Dict: å¹´åº¦è´¢åŠ¡æ€»è§ˆæ•°æ®
        """
        try:
            conn = self._get_connection()
            
            if year is None:
                year = datetime.now().year
                
            year_filter = "WHERE strftime('%Y', date) = ?"
            params = [str(year)]
            
            # è·å–å¹´åº¦æ”¶å…¥æ€»é¢
            income_query = f"""
            SELECT SUM(amount) as total_income, COUNT(*) as income_count
            FROM transactions 
            {year_filter} AND type = 'æ”¶å…¥'
            """
            
            # è·å–å¹´åº¦æ”¯å‡ºæ€»é¢
            expense_query = f"""
            SELECT SUM(ABS(amount)) as total_expense, COUNT(*) as expense_count
            FROM transactions 
            {year_filter} AND type = 'æ”¯å‡º'
            """
            
            # è·å–æœ€å¤§å•ç¬”æ”¶å…¥è¯¦æƒ…ï¼ˆåŒ…å«å¤‡æ³¨ï¼‰
            max_income_query = f"""
            SELECT amount as max_income, category, subcategory, date, note, account
            FROM transactions 
            {year_filter} AND type = 'æ”¶å…¥'
            ORDER BY amount DESC
            LIMIT 1
            """
            
            # è·å–æœ€å¤§å•ç¬”æ”¯å‡ºè¯¦æƒ…ï¼ˆåŒ…å«å¤‡æ³¨ï¼‰
            max_expense_query = f"""
            SELECT ABS(amount) as max_expense, category, subcategory, date, note, account
            FROM transactions 
            {year_filter} AND type = 'æ”¯å‡º'
            ORDER BY ABS(amount) DESC
            LIMIT 1
            """
            
            # è·å–æ€»äº¤æ˜“ç¬”æ•°
            total_transactions_query = f"""
            SELECT COUNT(*) as total_transactions
            FROM transactions 
            {year_filter}
            """
            
            # è·å–è´¦æˆ·ä½¿ç”¨æƒ…å†µ
            account_usage_query = f"""
            SELECT account, COUNT(*) as usage_count
            FROM transactions 
            {year_filter}
            GROUP BY account
            ORDER BY usage_count DESC
            """
            
            # è·å–åœ°ç‚¹æ¶ˆè´¹ç»Ÿè®¡ï¼ˆæ”¯å‡ºï¼‰
            location_stats_query = f"""
            SELECT address, COUNT(*) as location_count
            FROM transactions 
            {year_filter} AND type = 'æ”¯å‡º' AND address IS NOT NULL AND address != ''
            GROUP BY address
            ORDER BY location_count DESC
            LIMIT 5
            """
            
            # è·å–åˆ†ç±»æ”¯å‡ºç»Ÿè®¡ï¼ˆä¸€çº§åˆ†ç±»ï¼‰
            category_expense_query = f"""
            SELECT category, SUM(ABS(amount)) as category_expense
            FROM transactions 
            {year_filter} AND type = 'æ”¯å‡º'
            GROUP BY category
            ORDER BY category_expense DESC
            """
            
            # è·å–æœ€å¸¸è´­ä¹°ç‰©å“ï¼ˆé€šè¿‡å¤‡æ³¨ç»Ÿè®¡ï¼‰
            frequent_items_query = f"""
            SELECT note, COUNT(*) as note_count
            FROM transactions 
            {year_filter} AND type = 'æ”¯å‡º' AND note IS NOT NULL AND note != ''
            GROUP BY note
            ORDER BY note_count DESC
            LIMIT 1
            """
            
            # è·å–æ”¶å…¥æ¥æºåˆ†æï¼ˆå¤‡æ³¨ > äºŒçº§åˆ†ç±» > ä¸€çº§åˆ†ç±»ï¼‰
            income_source_query = f"""
            SELECT 
                CASE 
                    WHEN note IS NOT NULL AND note != '' THEN note
                    WHEN subcategory IS NOT NULL AND subcategory != '' THEN subcategory  
                    ELSE category
                END as income_source,
                SUM(amount) as total_amount,
                COUNT(*) as transaction_count
            FROM transactions 
            {year_filter} AND type = 'æ”¶å…¥'
            GROUP BY income_source
            ORDER BY total_amount DESC
            LIMIT 1
            """
            
            # æ‰§è¡ŒæŸ¥è¯¢
            income_result = pd.read_sql_query(income_query, conn, params=params)
            expense_result = pd.read_sql_query(expense_query, conn, params=params)
            max_income_result = pd.read_sql_query(max_income_query, conn, params=params)
            max_expense_result = pd.read_sql_query(max_expense_query, conn, params=params)
            total_transactions_result = pd.read_sql_query(total_transactions_query, conn, params=params)
            account_usage_result = pd.read_sql_query(account_usage_query, conn, params=params)
            location_stats_result = pd.read_sql_query(location_stats_query, conn, params=params)
            category_expense_result = pd.read_sql_query(category_expense_query, conn, params=params)
            frequent_items_result = pd.read_sql_query(frequent_items_query, conn, params=params)
            income_source_result = pd.read_sql_query(income_source_query, conn, params=params)
            
            conn.close()
            
            # æå–åŸºç¡€æ•°æ®
            total_income = float(income_result.iloc[0]['total_income'] or 0)
            income_count = int(income_result.iloc[0]['income_count'] or 0)
            
            total_expense = float(expense_result.iloc[0]['total_expense'] or 0)
            expense_count = int(expense_result.iloc[0]['expense_count'] or 0)
            
            total_transactions = int(total_transactions_result.iloc[0]['total_transactions'] or 0)
            
            # æå–æœ€é«˜æ”¶å…¥è¯¦æƒ…
            max_income_data = {
                'amount': float(max_income_result.iloc[0]['max_income'] or 0),
                'category': max_income_result.iloc[0]['category'] or '',
                'subcategory': max_income_result.iloc[0]['subcategory'] or '',
                'date': max_income_result.iloc[0]['date'] or '',
                'note': max_income_result.iloc[0]['note'] or '',
                'account': max_income_result.iloc[0]['account'] or ''
            } if not max_income_result.empty else {'amount': 0, 'category': '', 'subcategory': '', 'date': '', 'note': '', 'account': ''}
            
            # æå–æœ€é«˜æ”¯å‡ºè¯¦æƒ…
            max_expense_data = {
                'amount': float(max_expense_result.iloc[0]['max_expense'] or 0),
                'category': max_expense_result.iloc[0]['category'] or '',
                'subcategory': max_expense_result.iloc[0]['subcategory'] or '',
                'date': max_expense_result.iloc[0]['date'] or '',
                'note': max_expense_result.iloc[0]['note'] or '',
                'account': max_expense_result.iloc[0]['account'] or ''
            } if not max_expense_result.empty else {'amount': 0, 'category': '', 'subcategory': '', 'date': '', 'note': '', 'account': ''}
            
            # æå–è´¦æˆ·ä½¿ç”¨æƒ…å†µ
            account_usage = []
            total_account_usage = account_usage_result['usage_count'].sum() if not account_usage_result.empty else 0
            for _, row in account_usage_result.iterrows():
                account_usage.append({
                    'account': row['account'],
                    'usage_count': int(row['usage_count']),
                    'percentage': round(row['usage_count'] / total_account_usage * 100, 2) if total_account_usage > 0 else 0
                })
            
            # æå–åœ°ç‚¹æ¶ˆè´¹ç»Ÿè®¡
            location_stats = []
            total_location_count = location_stats_result['location_count'].sum() if not location_stats_result.empty else 0
            for _, row in location_stats_result.iterrows():
                location_stats.append({
                    'location': row['address'],
                    'count': int(row['location_count']),
                    'percentage': round(row['location_count'] / total_location_count * 100, 2) if total_location_count > 0 else 0
                })
            
            # æå–åˆ†ç±»æ”¯å‡ºç»Ÿè®¡
            category_expenses = []
            for _, row in category_expense_result.iterrows():
                category_expenses.append({
                    'category': row['category'],
                    'expense': float(row['category_expense'])
                })
            
            # æå–æœ€å¸¸è´­ä¹°ç‰©å“
            most_frequent_item = {
                'note': frequent_items_result.iloc[0]['note'] if not frequent_items_result.empty else '',
                'count': int(frequent_items_result.iloc[0]['note_count']) if not frequent_items_result.empty else 0
            }
            
            # æå–ä¸»è¦æ”¶å…¥æ¥æº
            main_income_source = {
                'source': income_source_result.iloc[0]['income_source'] if not income_source_result.empty else '',
                'amount': float(income_source_result.iloc[0]['total_amount']) if not income_source_result.empty else 0,
                'count': int(income_source_result.iloc[0]['transaction_count']) if not income_source_result.empty else 0,
                'percentage': round(float(income_source_result.iloc[0]['total_amount']) / total_income * 100, 2) if not income_source_result.empty and total_income > 0 else 0
            }
            
            # è®¡ç®—è¡ç”ŸæŒ‡æ ‡
            net_savings = total_income - total_expense
            savings_rate = (net_savings / total_income * 100) if total_income > 0 else 0
            avg_monthly_income = total_income / 12
            avg_monthly_expense = total_expense / 12
            avg_daily_expense = total_expense / 365 if total_expense > 0 else 0
            
            # ç®€åŒ–çš„èµ„äº§è´Ÿå€ºæ•°æ®ï¼ˆåŸºäºè´¦æˆ·ä½™é¢æ¦‚å¿µï¼‰
            # æ³¨ï¼šè¿™é‡Œå‡è®¾æ­£ä½™é¢ä¸ºèµ„äº§ï¼Œè´Ÿä½™é¢ä¸ºè´Ÿå€º
            total_assets = total_income  # ç®€åŒ–å¤„ç†
            total_liabilities = 0  # ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”æ ¹æ®å…·ä½“ä¸šåŠ¡é€»è¾‘
            net_assets = total_assets - total_liabilities
            
            # è·å–æ–°çš„åˆ†æç»´åº¦æ•°æ®
            time_analysis = self.get_time_consumption_analysis(year)
            behavior_analysis = self.get_consumption_behavior_analysis(year)
            growth_analysis = self.get_financial_growth_analysis(year)
            events_analysis = self.get_special_events_analysis(year)

            result = {
                'year': year,
                'annual_total_income': total_income,
                'annual_total_expense': total_expense,
                'annual_net_savings': net_savings,
                'annual_savings_rate': round(savings_rate, 2),
                'year_end_total_assets': total_assets,
                'year_end_total_liabilities': total_liabilities,
                'year_end_net_assets': net_assets,
                'avg_monthly_income': round(avg_monthly_income, 2),
                'avg_monthly_expense': round(avg_monthly_expense, 2),
                'avg_daily_expense': round(avg_daily_expense, 2),
                'annual_total_transactions': total_transactions,
                'max_single_income_data': max_income_data,
                'max_single_expense_data': max_expense_data,
                'income_transaction_count': income_count,
                'expense_transaction_count': expense_count,
                'account_usage': account_usage,
                'location_stats': location_stats,
                'category_expenses': category_expenses,
                'most_frequent_item': most_frequent_item,
                'main_income_source': main_income_source,
                # æ–°å¢çš„åˆ†æç»´åº¦
                'time_analysis': time_analysis,
                'behavior_analysis': behavior_analysis,
                'growth_analysis': growth_analysis,
                'events_analysis': events_analysis,
                # ä¿æŒå‘åå…¼å®¹
                'max_single_income': max_income_data['amount'],
                'max_single_expense': max_expense_data['amount']
            }
            
            logger.info(f"è·å–{year}å¹´åº¦è´¢åŠ¡æ€»è§ˆæ•°æ®æˆåŠŸ")
            return result
            
        except Exception as e:
            logger.error(f"è·å–å¹´åº¦è´¢åŠ¡æ€»è§ˆæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
    
    def get_annual_summary(self, year: Optional[int] = None) -> Dict:
        """è·å–å¹´åº¦æ€»ç»“
        
        Args:
            year: æŒ‡å®šå¹´ä»½
            
        Returns:
            Dict: å¹´åº¦æ€»ç»“æ•°æ®
        """
        try:
            if year is None:
                year = datetime.now().year
                
            # è·å–å„é¡¹åˆ†ææ•°æ®
            financial_overview = self.get_financial_overview(year)
            monthly_trend = self.get_monthly_trend(year)
            expense_categories = self.get_category_analysis('æ”¯å‡º', year)
            income_categories = self.get_category_analysis('æ”¶å…¥', year)
            account_analysis = self.get_account_analysis(year)
            location_analysis = self.get_location_analysis(year, 10)
            time_pattern = self.get_time_pattern_analysis(year)
            
            # è®¡ç®—æ€»ä½“ç»Ÿè®¡
            total_income = sum([month['income'] for month in monthly_trend['monthly_data'].values()])
            total_expense = sum([month['expense'] for month in monthly_trend['monthly_data'].values()])
            total_transactions = sum([month['transaction_count'] for month in monthly_trend['monthly_data'].values()])
            
            # æœ€é«˜æ”¯å‡ºæœˆä»½
            max_expense_month = max(monthly_trend['monthly_data'].items(), key=lambda x: x[1]['expense'])
            
            # æœ€é«˜æ”¶å…¥æœˆä»½
            max_income_month = max(monthly_trend['monthly_data'].items(), key=lambda x: x[1]['income'])
            
            result = {
                'year': year,
                'financial_overview': financial_overview,
                'overview': {
                    'total_income': total_income,
                    'total_expense': total_expense,
                    'net_income': total_income - total_expense,
                    'total_transactions': total_transactions,
                    'avg_monthly_expense': total_expense / 12,
                    'avg_monthly_income': total_income / 12,
                    'max_expense_month': {
                        'month': max_expense_month[0],
                        'amount': max_expense_month[1]['expense']
                    },
                    'max_income_month': {
                        'month': max_income_month[0],
                        'amount': max_income_month[1]['income']
                    }
                },
                'monthly_trend': monthly_trend,
                'expense_categories': expense_categories,
                'income_categories': income_categories,
                'account_analysis': account_analysis,
                'location_analysis': location_analysis,
                'time_pattern': time_pattern
            }
            
            logger.info(f"è·å–{year}å¹´åº¦æ€»ç»“æ•°æ®æˆåŠŸ")
            return result
            
        except Exception as e:
            logger.error(f"è·å–å¹´åº¦æ€»ç»“æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise
    
    def get_time_consumption_analysis(self, year: Optional[int] = None) -> Dict:
        """è·å–æ—¶é—´ç»´åº¦æ¶ˆè´¹åˆ†æ

        Args:
            year: æŒ‡å®šå¹´ä»½ï¼Œé»˜è®¤ä¸ºå½“å‰å¹´ä»½

        Returns:
            Dict: æ—¶é—´ç»´åº¦åˆ†ææ•°æ®
        """
        try:
            conn = self._get_connection()

            if year is None:
                year = datetime.now().year

            year_filter = "WHERE strftime('%Y', date) = ?"
            params = [str(year)]

            # æŒ‰å°æ—¶ç»Ÿè®¡
            hour_query = f"""
            SELECT
                strftime('%H', date) as hour,
                COUNT(*) as transaction_count,
                SUM(ABS(amount)) as total_amount
            FROM transactions
            {year_filter}
            GROUP BY hour
            ORDER BY hour
            """

            # æŒ‰æ˜ŸæœŸç»Ÿè®¡
            weekday_query = f"""
            SELECT
                strftime('%w', date) as weekday,
                COUNT(*) as transaction_count,
                SUM(ABS(amount)) as total_amount
            FROM transactions
            {year_filter}
            GROUP BY weekday
            ORDER BY weekday
            """

            # æŒ‰æœˆä»½å‰ä¸­åæœŸç»Ÿè®¡
            month_period_query = f"""
            SELECT
                CASE
                    WHEN CAST(strftime('%d', date) AS INTEGER) <= 10 THEN 'æœˆåˆ'
                    WHEN CAST(strftime('%d', date) AS INTEGER) <= 20 THEN 'æœˆä¸­'
                    ELSE 'æœˆæœ«'
                END as period,
                COUNT(*) as transaction_count,
                SUM(ABS(amount)) as total_amount
            FROM transactions
            {year_filter}
            GROUP BY period
            """

            # æŒ‰å­£èŠ‚ç»Ÿè®¡
            season_query = f"""
            SELECT
                CASE
                    WHEN CAST(strftime('%m', date) AS INTEGER) IN (3,4,5) THEN 'æ˜¥å¤©'
                    WHEN CAST(strftime('%m', date) AS INTEGER) IN (6,7,8) THEN 'å¤å¤©'
                    WHEN CAST(strftime('%m', date) AS INTEGER) IN (9,10,11) THEN 'ç§‹å¤©'
                    ELSE 'å†¬å¤©'
                END as season,
                COUNT(*) as transaction_count,
                SUM(ABS(amount)) as total_amount
            FROM transactions
            {year_filter}
            GROUP BY season
            """

            hour_df = pd.read_sql_query(hour_query, conn, params=params)
            weekday_df = pd.read_sql_query(weekday_query, conn, params=params)
            month_period_df = pd.read_sql_query(month_period_query, conn, params=params)
            season_df = pd.read_sql_query(season_query, conn, params=params)
            conn.close()

            # å¤„ç†å°æ—¶æ•°æ®ï¼Œæ‰¾å‡ºæ¶ˆè´¹é«˜å³°æ—¶é—´
            peak_hours = hour_df.nlargest(3, 'total_amount')
            peak_hour = peak_hours.iloc[0] if not peak_hours.empty else None

            # å¤„ç†æ˜ŸæœŸæ•°æ®
            weekday_names = ['å‘¨æ—¥', 'å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­']
            peak_weekday = weekday_df.nlargest(1, 'total_amount').iloc[0] if not weekday_df.empty else None

            # å¤„ç†æœˆä»½å‘¨æœŸæ•°æ®
            peak_period = month_period_df.nlargest(1, 'total_amount').iloc[0] if not month_period_df.empty else None

            # å¤„ç†å­£èŠ‚æ•°æ®
            peak_season = season_df.nlargest(1, 'total_amount').iloc[0] if not season_df.empty else None

            result = {
                'year': year,
                'peak_hour': {
                    'hour': int(peak_hour['hour']) if peak_hour is not None else None,
                    'amount': float(peak_hour['total_amount']) if peak_hour is not None else 0,
                    'count': int(peak_hour['transaction_count']) if peak_hour is not None else 0
                },
                'peak_weekday': {
                    'weekday': weekday_names[int(peak_weekday['weekday'])] if peak_weekday is not None else None,
                    'amount': float(peak_weekday['total_amount']) if peak_weekday is not None else 0,
                    'count': int(peak_weekday['transaction_count']) if peak_weekday is not None else 0
                },
                'peak_period': {
                    'period': peak_period['period'] if peak_period is not None else None,
                    'amount': float(peak_period['total_amount']) if peak_period is not None else 0,
                    'count': int(peak_period['transaction_count']) if peak_period is not None else 0
                },
                'peak_season': {
                    'season': peak_season['season'] if peak_season is not None else None,
                    'amount': float(peak_season['total_amount']) if peak_season is not None else 0,
                    'count': int(peak_season['transaction_count']) if peak_season is not None else 0
                }
            }

            logger.info(f"è·å–{year}å¹´æ—¶é—´ç»´åº¦æ¶ˆè´¹åˆ†ææ•°æ®æˆåŠŸ")
            return result

        except Exception as e:
            logger.error(f"è·å–æ—¶é—´ç»´åº¦æ¶ˆè´¹åˆ†ææ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise

    def get_consumption_behavior_analysis(self, year: Optional[int] = None) -> Dict:
        """è·å–æ¶ˆè´¹è¡Œä¸ºæ¨¡å¼åˆ†æ

        Args:
            year: æŒ‡å®šå¹´ä»½ï¼Œé»˜è®¤ä¸ºå½“å‰å¹´ä»½

        Returns:
            Dict: æ¶ˆè´¹è¡Œä¸ºåˆ†ææ•°æ®
        """
        try:
            conn = self._get_connection()

            if year is None:
                year = datetime.now().year

            year_filter = "WHERE strftime('%Y', date) = ?"
            params = [str(year)]

            # è·å–æ‰€æœ‰æ”¯å‡ºäº¤æ˜“
            expense_query = f"""
            SELECT
                DATE(date) as date,
                ABS(amount) as amount,
                COUNT(*) as daily_count
            FROM transactions
            {year_filter} AND type = 'æ”¯å‡º'
            GROUP BY DATE(date)
            ORDER BY date
            """

            expense_df = pd.read_sql_query(expense_query, conn, params=params)

            if expense_df.empty:
                conn.close()
                return {
                    'year': year,
                    'consumption_type': 'æš‚æ— æ•°æ®',
                    'impulse_days': 0,
                    'stability_score': 0,
                    'max_consecutive_days': 0
                }

            # åˆ†ææ¶ˆè´¹é¢‘ç‡å’Œé‡‘é¢æ¨¡å¼
            total_amount = expense_df['amount'].sum()
            total_transactions = expense_df['daily_count'].sum()
            avg_transaction = total_amount / total_transactions if total_transactions > 0 else 0

            # å°é¢é«˜é¢‘ vs å¤§é¢ä½é¢‘åˆ†æ
            small_amount_threshold = avg_transaction * 0.5
            large_amount_threshold = avg_transaction * 2

            small_transactions = expense_df[expense_df['amount'] <= small_amount_threshold]['daily_count'].sum()
            large_transactions = expense_df[expense_df['amount'] >= large_amount_threshold]['daily_count'].sum()

            # åˆ¤æ–­æ¶ˆè´¹ç±»å‹
            if small_transactions > large_transactions * 2:
                consumption_type = "å°ç¡®å¹¸æ”¶é›†è€…"
                type_description = f"{int(small_transactions/total_transactions*100)}%çš„æ¶ˆè´¹éƒ½æ˜¯å°é¢å¿«ä¹"
            elif large_transactions > small_transactions:
                consumption_type = "å“è´¨ç”Ÿæ´»å®¶"
                type_description = f"åçˆ±å¤§é¢æ¶ˆè´¹ï¼Œè¿½æ±‚å“è´¨ç”Ÿæ´»"
            else:
                consumption_type = "å‡è¡¡æ¶ˆè´¹è€…"
                type_description = f"å¤§å°é¢æ¶ˆè´¹æ¯”è¾ƒå‡è¡¡"

            # å†²åŠ¨æ¶ˆè´¹æ£€æµ‹ï¼ˆå•æ—¥å¤šç¬”äº¤æ˜“ï¼‰
            impulse_days = len(expense_df[expense_df['daily_count'] >= 3])
            max_daily_transactions = expense_df['daily_count'].max()
            max_impulse_day = expense_df[expense_df['daily_count'] == max_daily_transactions].iloc[0] if max_daily_transactions > 1 else None

            # æ¶ˆè´¹ç¨³å®šæ€§åˆ†æï¼ˆæœˆåº¦æ”¯å‡ºæ ‡å‡†å·®ï¼‰
            expense_df['month'] = pd.to_datetime(expense_df['date']).dt.to_period('M')
            monthly_expense = expense_df.groupby('month')['amount'].sum()
            stability_score = 100 - min(100, (monthly_expense.std() / monthly_expense.mean() * 100)) if len(monthly_expense) > 1 else 100

            # è¿ç»­æ¶ˆè´¹å¤©æ•°åˆ†æ
            expense_df['date_dt'] = pd.to_datetime(expense_df['date'])
            expense_df = expense_df.sort_values('date_dt')

            consecutive_days = 1
            max_consecutive_days = 1

            for i in range(1, len(expense_df)):
                if (expense_df.iloc[i]['date_dt'] - expense_df.iloc[i-1]['date_dt']).days == 1:
                    consecutive_days += 1
                    max_consecutive_days = max(max_consecutive_days, consecutive_days)
                else:
                    consecutive_days = 1

            conn.close()

            result = {
                'year': year,
                'consumption_type': consumption_type,
                'type_description': type_description,
                'impulse_days': int(impulse_days),
                'max_daily_transactions': int(max_daily_transactions),
                'max_impulse_day': {
                    'date': max_impulse_day['date'] if max_impulse_day is not None else None,
                    'count': int(max_impulse_day['daily_count']) if max_impulse_day is not None else 0,
                    'amount': float(max_impulse_day['amount']) if max_impulse_day is not None else 0
                },
                'stability_score': round(stability_score, 1),
                'max_consecutive_days': int(max_consecutive_days),
                'avg_transaction_amount': round(avg_transaction, 2)
            }

            logger.info(f"è·å–{year}å¹´æ¶ˆè´¹è¡Œä¸ºåˆ†ææ•°æ®æˆåŠŸ")
            return result

        except Exception as e:
            logger.error(f"è·å–æ¶ˆè´¹è¡Œä¸ºåˆ†ææ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise

    def get_financial_growth_analysis(self, year: Optional[int] = None) -> Dict:
        """è·å–è´¢åŠ¡æˆé•¿è½¨è¿¹åˆ†æ

        Args:
            year: æŒ‡å®šå¹´ä»½ï¼Œé»˜è®¤ä¸ºå½“å‰å¹´ä»½

        Returns:
            Dict: è´¢åŠ¡æˆé•¿åˆ†ææ•°æ®
        """
        try:
            conn = self._get_connection()

            if year is None:
                year = datetime.now().year

            year_filter = "WHERE strftime('%Y', date) = ?"
            params = [str(year)]

            # æŒ‰æœˆç»Ÿè®¡æ”¶æ”¯
            monthly_query = f"""
            SELECT
                strftime('%m', date) as month,
                type,
                SUM(amount) as total_amount,
                COUNT(*) as transaction_count,
                AVG(ABS(amount)) as avg_amount
            FROM transactions
            {year_filter}
            GROUP BY month, type
            ORDER BY month
            """

            monthly_df = pd.read_sql_query(monthly_query, conn, params=params)
            conn.close()

            if monthly_df.empty:
                return {
                    'year': year,
                    'peak_income_month': None,
                    'peak_expense_month': None,
                    'savings_trend': 'æš‚æ— æ•°æ®',
                    'consumption_upgrade': 'æš‚æ— æ•°æ®'
                }

            # åˆ†ç¦»æ”¶å…¥å’Œæ”¯å‡ºæ•°æ®
            income_df = monthly_df[monthly_df['type'] == 'æ”¶å…¥'].copy()
            expense_df = monthly_df[monthly_df['type'] == 'æ”¯å‡º'].copy()

            # æ‰¾å‡ºæ”¶å…¥å’Œæ”¯å‡ºå³°å€¼æœˆä»½
            peak_income_month = None
            peak_expense_month = None

            if not income_df.empty:
                peak_income = income_df.loc[income_df['total_amount'].idxmax()]
                peak_income_month = {
                    'month': int(peak_income['month']),
                    'amount': float(peak_income['total_amount']),
                    'count': int(peak_income['transaction_count'])
                }

            if not expense_df.empty:
                expense_df['abs_amount'] = expense_df['total_amount'].abs()
                peak_expense = expense_df.loc[expense_df['abs_amount'].idxmax()]
                peak_expense_month = {
                    'month': int(peak_expense['month']),
                    'amount': float(peak_expense['abs_amount']),
                    'count': int(peak_expense['transaction_count'])
                }

            # å‚¨è“„ç‡è¶‹åŠ¿åˆ†æ
            monthly_summary = []
            for month in range(1, 13):
                month_str = f"{month:02d}"
                month_income = income_df[income_df['month'] == month_str]['total_amount'].sum()
                month_expense = expense_df[expense_df['month'] == month_str]['total_amount'].abs().sum()
                month_savings = month_income - month_expense
                savings_rate = (month_savings / month_income * 100) if month_income > 0 else 0

                monthly_summary.append({
                    'month': month,
                    'income': month_income,
                    'expense': month_expense,
                    'savings': month_savings,
                    'savings_rate': savings_rate
                })

            # è®¡ç®—å‚¨è“„ç‡è¶‹åŠ¿
            valid_months = [m for m in monthly_summary if m['income'] > 0]
            if len(valid_months) >= 2:
                first_half_rate = sum(m['savings_rate'] for m in valid_months[:len(valid_months)//2]) / (len(valid_months)//2)
                second_half_rate = sum(m['savings_rate'] for m in valid_months[len(valid_months)//2:]) / (len(valid_months) - len(valid_months)//2)

                if second_half_rate > first_half_rate + 5:
                    savings_trend = f"å‚¨è“„èƒ½åŠ›åœ¨è¿›æ­¥ï¼Œä»{first_half_rate:.1f}%æ¶¨åˆ°{second_half_rate:.1f}%"
                elif first_half_rate > second_half_rate + 5:
                    savings_trend = f"å‚¨è“„ç‡æœ‰æ‰€ä¸‹é™ï¼Œä»{first_half_rate:.1f}%é™åˆ°{second_half_rate:.1f}%"
                else:
                    savings_trend = f"å‚¨è“„ç‡æ¯”è¾ƒç¨³å®šï¼Œä¿æŒåœ¨{(first_half_rate + second_half_rate)/2:.1f}%å·¦å³"
            else:
                savings_trend = "æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†æè¶‹åŠ¿"

            # æ¶ˆè´¹å‡çº§åˆ†æ
            if not expense_df.empty and len(expense_df) >= 2:
                first_half_avg = expense_df[:len(expense_df)//2]['avg_amount'].mean()
                second_half_avg = expense_df[len(expense_df)//2:]['avg_amount'].mean()

                if second_half_avg > first_half_avg * 1.2:
                    consumption_upgrade = f"æ¶ˆè´¹åœ¨å‡çº§ï¼Œå¹³å‡å•ç¬”ä»Â¥{first_half_avg:.0f}æ¶¨åˆ°Â¥{second_half_avg:.0f} <img src=\"/CuteEmoji/ğŸ†™_AgADbUkAAuaZWEs.webp\" alt=\"ğŸ†™\" style=\"width: 14px; height: 14px; display: inline-block; margin-left: 4px; vertical-align: middle;\" />"
                elif first_half_avg > second_half_avg * 1.2:
                    consumption_upgrade = f"æ¶ˆè´¹æ›´ç†æ€§äº†ï¼Œå¹³å‡å•ç¬”ä»Â¥{first_half_avg:.0f}é™åˆ°Â¥{second_half_avg:.0f} <img src=\"/CuteEmoji/ğŸ‘_AgAD3kUAAksEWUs.webp\" alt=\"ğŸ‘\" style=\"width: 14px; height: 14px; display: inline-block; margin-left: 4px; vertical-align: middle;\" />"
                else:
                    consumption_upgrade = f"æ¶ˆè´¹æ°´å¹³æ¯”è¾ƒç¨³å®šï¼Œå¹³å‡å•ç¬”Â¥{(first_half_avg + second_half_avg)/2:.0f}å·¦å³ <img src=\"/CuteEmoji/ğŸ˜Œ_AgADA0cAAgG0WUs.webp\" alt=\"ğŸ˜Œ\" style=\"width: 14px; height: 14px; display: inline-block; margin-left: 4px; vertical-align: middle;\" />"
            else:
                consumption_upgrade = "æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†ææ¶ˆè´¹å˜åŒ–"

            result = {
                'year': year,
                'peak_income_month': peak_income_month,
                'peak_expense_month': peak_expense_month,
                'savings_trend': savings_trend,
                'consumption_upgrade': consumption_upgrade,
                'monthly_summary': monthly_summary
            }

            logger.info(f"è·å–{year}å¹´è´¢åŠ¡æˆé•¿åˆ†ææ•°æ®æˆåŠŸ")
            return result

        except Exception as e:
            logger.error(f"è·å–è´¢åŠ¡æˆé•¿åˆ†ææ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise

    def get_special_events_analysis(self, year: Optional[int] = None) -> Dict:
        """è·å–ç‰¹æ®Šäº‹ä»¶ä¸çºªå¿µæ—¶åˆ»åˆ†æ

        Args:
            year: æŒ‡å®šå¹´ä»½ï¼Œé»˜è®¤ä¸ºå½“å‰å¹´ä»½

        Returns:
            Dict: ç‰¹æ®Šäº‹ä»¶åˆ†ææ•°æ®
        """
        try:
            conn = self._get_connection()

            if year is None:
                year = datetime.now().year

            year_filter = "WHERE strftime('%Y', date) = ?"
            params = [str(year)]

            # è·å–æ¯æ—¥æ”¯å‡ºæ•°æ®
            daily_expense_query = f"""
            SELECT
                DATE(date) as date,
                SUM(ABS(amount)) as daily_expense,
                COUNT(*) as transaction_count
            FROM transactions
            {year_filter} AND type = 'æ”¯å‡º'
            GROUP BY DATE(date)
            ORDER BY daily_expense DESC
            """

            daily_df = pd.read_sql_query(daily_expense_query, conn, params=params)

            # å‘¨æœ«vså·¥ä½œæ—¥åˆ†æ
            weekend_workday_query = f"""
            SELECT
                CASE
                    WHEN strftime('%w', date) IN ('0', '6') THEN 'å‘¨æœ«'
                    ELSE 'å·¥ä½œæ—¥'
                END as day_type,
                AVG(ABS(amount)) as avg_amount,
                COUNT(*) as transaction_count,
                SUM(ABS(amount)) as total_amount
            FROM transactions
            {year_filter} AND type = 'æ”¯å‡º'
            GROUP BY day_type
            """

            weekend_df = pd.read_sql_query(weekend_workday_query, conn, params=params)
            conn.close()

            # ç‰¹æ®Šæ—¥æœŸå®šä¹‰ - åŒ…å«ä¼ ç»ŸèŠ‚æ—¥ã€ç°ä»£èŠ‚æ—¥ã€ç½‘ç»œèŠ‚æ—¥
            special_dates = {
                # ä¼ ç»ŸèŠ‚æ—¥
                f'{year}-01-01': 'å…ƒæ—¦',
                f'{year}-05-01': 'åŠ³åŠ¨èŠ‚',
                f'{year}-10-01': 'å›½åº†èŠ‚',
                f'{year}-12-25': 'åœ£è¯èŠ‚',

                # æƒ…ä¾£èŠ‚æ—¥
                f'{year}-02-14': 'æƒ…äººèŠ‚',
                f'{year}-03-14': 'ç™½è‰²æƒ…äººèŠ‚',
                f'{year}-05-20': '520ç½‘ç»œæƒ…äººèŠ‚',
                f'{year}-05-21': '521ç½‘ç»œæƒ…äººèŠ‚',
                f'{year}-08-07': 'ä¸ƒå¤•èŠ‚',  # å†œå†ä¸ƒæœˆåˆä¸ƒï¼Œè¿™é‡Œç”¨å…¬å†è¿‘ä¼¼

                # è´­ç‰©èŠ‚æ—¥
                f'{year}-06-18': '618è´­ç‰©èŠ‚',
                f'{year}-08-18': '818è´­ç‰©èŠ‚',
                f'{year}-11-11': 'åŒ11è´­ç‰©èŠ‚',
                f'{year}-12-12': 'åŒ12è´­ç‰©èŠ‚',

                # å…¶ä»–ç‰¹æ®Šæ—¥æœŸ
                f'{year}-03-08': 'å¦‡å¥³èŠ‚',
                f'{year}-06-01': 'å„¿ç«¥èŠ‚',
                f'{year}-09-10': 'æ•™å¸ˆèŠ‚',
                f'{year}-11-24': 'é»‘è‰²æ˜ŸæœŸäº”',  # æ„Ÿæ©èŠ‚åç¬¬ä¸€å¤©ï¼Œè¿™é‡Œç”¨å›ºå®šæ—¥æœŸè¿‘ä¼¼

                # ç½‘ç»œèŠ‚æ—¥
                f'{year}-01-11': 'å…‰æ£èŠ‚å‰å¥',
                f'{year}-04-01': 'æ„šäººèŠ‚',
                f'{year}-05-04': 'é’å¹´èŠ‚',
                f'{year}-12-24': 'å¹³å®‰å¤œ'
            }

            # åˆ†æç‰¹æ®Šæ—¥æœŸæ¶ˆè´¹
            special_events = []
            if not daily_df.empty:
                for date_str, event_name in special_dates.items():
                    event_data = daily_df[daily_df['date'] == date_str]
                    if not event_data.empty:
                        event_expense = event_data.iloc[0]
                        avg_daily_expense = daily_df['daily_expense'].mean()

                        if event_expense['daily_expense'] > avg_daily_expense * 1.5:
                            special_events.append({
                                'date': date_str,
                                'event': event_name,
                                'amount': float(event_expense['daily_expense']),
                                'count': int(event_expense['transaction_count']),
                                'multiplier': round(event_expense['daily_expense'] / avg_daily_expense, 1)
                            })

            # TOP5ç ´äº§æ—¥
            top_expense_days = []
            if not daily_df.empty:
                top_5 = daily_df.head(5)
                for _, row in top_5.iterrows():
                    date_obj = datetime.strptime(row['date'], '%Y-%m-%d')
                    top_expense_days.append({
                        'date': row['date'],
                        'month': date_obj.month,
                        'day': date_obj.day,
                        'amount': float(row['daily_expense']),
                        'count': int(row['transaction_count'])
                    })

            # å‘¨æœ«vså·¥ä½œæ—¥å¯¹æ¯”
            weekend_vs_workday = {}
            if not weekend_df.empty:
                weekend_data = weekend_df[weekend_df['day_type'] == 'å‘¨æœ«']
                workday_data = weekend_df[weekend_df['day_type'] == 'å·¥ä½œæ—¥']

                if not weekend_data.empty and not workday_data.empty:
                    weekend_avg = weekend_data.iloc[0]['avg_amount']
                    workday_avg = workday_data.iloc[0]['avg_amount']

                    if weekend_avg > workday_avg:
                        ratio = weekend_avg / workday_avg
                        weekend_vs_workday = {
                            'pattern': 'å‘¨æœ«æ›´çˆ±èŠ±é’±',
                            'description': f'å‘¨æœ«æ¶ˆè´¹æ¯”å·¥ä½œæ—¥å¤š{ratio:.1f}å€',
                            'weekend_avg': float(weekend_avg),
                            'workday_avg': float(workday_avg)
                        }
                    else:
                        ratio = workday_avg / weekend_avg
                        weekend_vs_workday = {
                            'pattern': 'å·¥ä½œæ—¥æ¶ˆè´¹æ›´å¤š',
                            'description': f'å·¥ä½œæ—¥æ¶ˆè´¹æ¯”å‘¨æœ«å¤š{ratio:.1f}å€',
                            'weekend_avg': float(weekend_avg),
                            'workday_avg': float(workday_avg)
                        }

            result = {
                'year': year,
                'special_events': special_events,
                'top_expense_days': top_expense_days,
                'weekend_vs_workday': weekend_vs_workday
            }

            logger.info(f"è·å–{year}å¹´ç‰¹æ®Šäº‹ä»¶åˆ†ææ•°æ®æˆåŠŸ")
            return result

        except Exception as e:
            logger.error(f"è·å–ç‰¹æ®Šäº‹ä»¶åˆ†ææ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise

    def get_available_years(self) -> List[int]:
        """è·å–æ•°æ®åº“ä¸­å­˜åœ¨äº¤æ˜“æ•°æ®çš„æ‰€æœ‰å¹´ä»½

        Returns:
            List[int]: å¯ç”¨å¹´ä»½åˆ—è¡¨ï¼ŒæŒ‰é™åºæ’åˆ—ï¼ˆæœ€æ–°å¹´ä»½åœ¨å‰ï¼‰
        """
        try:
            conn = self._get_connection()

            query = """
            SELECT DISTINCT strftime('%Y', date) as year
            FROM transactions
            WHERE date IS NOT NULL
            ORDER BY year DESC
            """

            df = pd.read_sql_query(query, conn)
            conn.close()

            if df.empty:
                logger.warning("æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•äº¤æ˜“æ•°æ®")
                return []

            years = [int(year) for year in df['year'].tolist()]
            logger.info(f"æ‰¾åˆ°å¯ç”¨å¹´ä»½: {years}")
            return years

        except Exception as e:
            logger.error(f"è·å–å¯ç”¨å¹´ä»½æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise

    def get_daily_data(self, year: Optional[int] = None) -> Dict:
        """è·å–æ¯æ—¥æ”¶æ”¯æ•°æ®ï¼Œç”¨äºçƒ­åŠ›å›¾æ˜¾ç¤º

        Args:
            year: æŒ‡å®šå¹´ä»½ï¼Œé»˜è®¤ä¸ºå½“å‰å¹´ä»½

        Returns:
            Dict: æ¯æ—¥æ•°æ®
        """
        try:
            conn = self._get_connection()

            if year is None:
                year = datetime.now().year

            query = """
            SELECT
                DATE(date) as date,
                type,
                SUM(amount) as total_amount,
                COUNT(*) as transaction_count
            FROM transactions
            WHERE strftime('%Y', date) = ?
            GROUP BY DATE(date), type
            ORDER BY DATE(date)
            """

            params = (str(year),)
            df = pd.read_sql_query(query, conn, params=params)
            conn.close()

            # å¤„ç†æ•°æ®ï¼ŒæŒ‰æ—¥æœŸç»„ç»‡
            daily_data = {}
            
            for _, row in df.iterrows():
                date_str = row['date']
                transaction_type = row['type']
                amount = float(row['total_amount'])
                count = int(row['transaction_count'])
                
                if date_str not in daily_data:
                    daily_data[date_str] = {
                        'date': date_str,
                        'income': 0,
                        'expense': 0,
                        'income_count': 0,
                        'expense_count': 0
                    }
                
                if transaction_type == 'æ”¶å…¥':
                    daily_data[date_str]['income'] = amount
                    daily_data[date_str]['income_count'] = count
                elif transaction_type == 'æ”¯å‡º':
                    # æ”¯å‡ºé‡‘é¢å–ç»å¯¹å€¼ï¼Œç¡®ä¿ä¸ºæ­£æ•°
                    daily_data[date_str]['expense'] = abs(amount)
                    daily_data[date_str]['expense_count'] = count
            
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
            result = {
                'year': year,
                'daily_data': list(daily_data.values())
            }
            
            logger.info(f"è·å–{year}å¹´æ¯æ—¥æ•°æ®æˆåŠŸï¼Œå…±{len(daily_data)}å¤©æœ‰äº¤æ˜“è®°å½•")
            return result
            
        except Exception as e:
            logger.error(f"è·å–æ¯æ—¥æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            raise